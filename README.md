# Projet P8 â€“ RÃ©alisez un traitement dans un environnement Big Data sur le Cloud

## ğŸ¯ Objectif du projet

L'objectif principal est de concevoir et de dÃ©ployer une chaÃ®ne de traitement de donnÃ©es Ã  grande Ã©chelle dans un environnement Big Data sur le cloud. Il s'agit de simuler le passage Ã  l'Ã©chelle d'un pipeline de traitement d'images en utilisant des outils adaptÃ©s au traitement distribuÃ©.

---

## ğŸ§° Technologies et outils utilisÃ©s

- **Langage de programmation** : Python
- **Framework de traitement distribuÃ©** : PySpark
- **Cloud Provider** : Amazon Web Services (AWS)
  - **Stockage** : Amazon S3
  - **Traitement** : Amazon EMR (Elastic MapReduce)
- **Environnement de dÃ©veloppement** : Jupyter Notebook

---

## ğŸ—‚ï¸ Contenu du dÃ©pÃ´t

- `Milan_Nicolas_1_notebook_032025.ipynb` : Notebook Jupyter contenant l'ensemble du pipeline de traitement, depuis l'ingestion des donnÃ©es jusqu'Ã  la rÃ©duction de dimension.
- `Milan_Nicolas_3_presentation_032025.pdf` : PrÃ©sentation synthÃ©tique du projet, incluant les choix technologiques, l'architecture mise en place et les rÃ©sultats obtenus.

---

## ğŸ—ï¸ Architecture mise en place

Le pipeline de traitement est dÃ©ployÃ© sur un cluster Amazon EMR, permettant de bÃ©nÃ©ficier de la puissance du traitement distribuÃ© avec PySpark. Les donnÃ©es sont stockÃ©es et rÃ©cupÃ©rÃ©es depuis Amazon S3, assurant une scalabilitÃ© et une disponibilitÃ© optimales.

---

## ğŸ“Š RÃ©sultats obtenus

- **ScalabilitÃ©** : Le passage Ã  l'Ã©chelle est facilitÃ© grÃ¢ce Ã  l'utilisation de PySpark et d'AWS EMR, permettant de traiter un grand volume d'images en parallÃ¨le.
- **Performance** : La rÃ©duction de dimension via l'ACP permet de diminuer la taille des donnÃ©es tout en conservant une reprÃ©sentation pertinente pour des tÃ¢ches ultÃ©rieures telles que la classification.
- **FlexibilitÃ©** : L'architecture mise en place est modulable et peut Ãªtre adaptÃ©e pour intÃ©grer d'autres types de donnÃ©es ou de traitements.

---
